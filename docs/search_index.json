[["index.html", "Twitter API Academic Research access with R Chapter 1 About 1.1 Book 1.2 Author", " Twitter API Academic Research access with R Francesco Bailo 2022-03-07 Chapter 1 About 1.1 Book This book offers some practical understanding on how to access the Twitter API with R. It assumes an Academic Research access but also some familiarity with R. If you are a student or an academic you can get more information on how to apply here. The book is based on the official Twitter documentation that you can access here. The code used in this book doesn’t rely on any ad-hoc package to access the Twitter API. This probably requries some more work on the user side but it also allows for more flexibility in defining and setting API queries and in responding to API changes. The code used in this book relies on three generalist packages The httr package (Wickham 2020) to deal with HTTP requests; The dplyr package (Wickham et al. 2021) to manipulate data objects in R; and The jsonlite package (Ooms 2022) to deal with JSON-formatted data objects. This book is very much a working in progress. For suggestions, comments or if you note a mistake, please create an issue here. 1.1.1 Twitter relationships In collecting Twitter data using the API, there are a number of entry points. Each node in the diagram indicate a possible entry point with arrows indicating the type of API requests necessary to crawl the graph. Of course there are many other entry points. A good place to see a complete list is the official Twitter API endpoint map. 1.2 Author Francesco Bailo is Lecturer of Digital and Social Media at the University of Technology Sydney, Australia. His research focuses on the use of digital and social media in politics. He obtained his PhD in 2017 at the University of Sydney, Australia. References "],["first-steps.html", "Chapter 2 First steps 2.1 Packages 2.2 Credentials 2.3 Interrogating the Twitter API", " Chapter 2 First steps Chapter progress bar ████████████████████████████░░ 95% 2.1 Packages The R code relies on generalist packages to access the API and manipulate the response. library(&quot;httr&quot;) library(&quot;dplyr&quot;) library(&quot;jsonlite&quot;) If you don’t have these packages already install, you need to run install.packages(&quot;httr&quot;) install.packages(&quot;jsonlite&quot;) install.packages(&quot;dplyr&quot;) 2.2 Credentials Let’s store our bearer token in an environment variable (let’s call it BEARER_TOKEN) Sys.setenv(BEARER_TOKEN = &quot;copy-your-bearer-token-here&quot;) We are then able to get the token back with Sys.getenv(&quot;BEARER_TOKEN&quot;) The idea is to run Sys.setenv() from our console before running our scripts (that is, every time!) so that our token is never added to a script file. Of course, if you don’t care you can just store it in a regular variable. 2.3 Interrogating the Twitter API The Twitter API accept two methods to exchange information: POST and GET. Intuitively, with the POST method we send information to a server while with the GET method we retrieve information. With the Twitter API, the GET method is used more frequently. Still, we need to use the POST method to define our search rules before we GET the Filtered stream. This is how a GET request using the httr package looks like: httr::GET(url, httr::add_headers(.headers = headers), query = params) The url is a simple character variable while headers and params are lists. But let’s send a GET request! We need first to set the URL, specify our request headers (these are not going to change, so you can place at the top of your document) and set the parameters fo the query. url &lt;- &quot;https://api.twitter.com/2/tweets/counts/recent&quot; headers &lt;- c(`Authorization` = sprintf(&#39;Bearer %s&#39;, Sys.getenv(&quot;BEARER_TOKEN&quot;))) params &lt;- list(query = &quot;from:TwitterDev&quot;, granularity = &quot;day&quot;) What are we doing here? With url we specify the endpoint we want to use for this API request. The Twitter API has several endpoints. Note that sometimes we need to include parameters here instead of passing them through the HTTP query. headers is the first layer of information that we send over to the server. In this case it contains our token. If this is accepted - the status of the request is 200 OK - then the API is ready to process our request. If the token is not accepted we get as status 401 Unauthorized. Note that these error codes and messages define the status of the HTTP request. The Twitter API has a different set of error codes. In this sense, we can get a 200 OK from the HTTP layer and still get an error (e.g. 429 Too Many Requests) from the API layer (think in stacks!). With params we define the queries with want to append to the URL. Functionally, you can imagine that the list of key-value pairs what we define in list object params are appended after the string we set with url and a ? (for example, in https://example.com/over/there?name=ferret the query is defined by the key-value name=ferret). Now we can add these as attributes to the function GET and collect the response in res. res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) By printing res we see details about the HTTP response (but not yet the API response or the content returned from the API). print(res) ## Response [https://api.twitter.com/2/tweets/counts/recent?query=from%3ATwitterDev&amp;granularity=day] ## Date: 2022-03-06 06:10 ## Status: 200 ## Content-Type: application/json; charset=utf-8 ## Size: 729 B If our request was authorised we should get Status: 200 if our request was not authorised (likely because your token was not correctly specified) we should instead get Status: 401 Assuming, that we got an OK from the HTTP layer, then we can access the content we receive as a response from the API layer. We access it with the function httr::content(). obj.json &lt;- httr::content(res, as = &quot;text&quot;) Now by default the Twitter API responses are in JSON format, which looks like this: print(jsonlite::prettify(obj.json, indent = 4)) ## { ## &quot;data&quot;: [ ## { ## &quot;end&quot;: &quot;2022-02-28T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-02-27T06:10:42.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-01T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-02-28T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 1 ## }, ## { ## &quot;end&quot;: &quot;2022-03-02T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-01T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-03T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-02T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-04T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-03T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-05T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-04T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-06T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-05T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-06T06:10:42.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-06T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## } ## ], ## &quot;meta&quot;: { ## &quot;total_tweet_count&quot;: 1 ## } ## } ## We can use the jsonlite package to translate the JSON-formatted string into an R object with obj.r &lt;- jsonlite::fromJSON(obj.json) print(obj.r) ## $data ## end start tweet_count ## 1 2022-02-28T00:00:00.000Z 2022-02-27T06:10:42.000Z 0 ## 2 2022-03-01T00:00:00.000Z 2022-02-28T00:00:00.000Z 1 ## 3 2022-03-02T00:00:00.000Z 2022-03-01T00:00:00.000Z 0 ## 4 2022-03-03T00:00:00.000Z 2022-03-02T00:00:00.000Z 0 ## 5 2022-03-04T00:00:00.000Z 2022-03-03T00:00:00.000Z 0 ## 6 2022-03-05T00:00:00.000Z 2022-03-04T00:00:00.000Z 0 ## 7 2022-03-06T00:00:00.000Z 2022-03-05T00:00:00.000Z 0 ## 8 2022-03-06T06:10:42.000Z 2022-03-06T00:00:00.000Z 0 ## ## $meta ## $meta$total_tweet_count ## [1] 1 And this is information on the number of tweets posted by (TwitterDev?) in the days before our request. "],["data-management.html", "Chapter 3 Data management 3.1 JSON 3.2 Storage, analysis and acccess 3.3 Data ownership and ethics", " Chapter 3 Data management Chapter progress bar ██████████░░░░░░░░░░░░░░░░░░░░ 35% Once we got access to the Twitter API we must start planning about data management. The Twitter API can potentially return a huge amount of data (the current limits for Academic access are set to 10,000,000 tweets a month). What do we do with it? Where do we store it but also should we store it? 3.1 JSON The default format for data loads from the Twitter API is JSON. A JSON (JavaScript Object Notation) file is a plain text file - so you can open it with any text editor. Information is structured through nesting like HTML or XML. JSON can’t be naturally manipulated in R. Access and analysis in R involves reading the text in but also transforming it into R vector types (e.g. logical, integer, double, character) and structures (e.g. atomic vector, data.frame, matrix, list) - which is not painless! 3.1.1 Read your JSON files: Tweets json_data_dir &lt;- &quot;json_data&quot; if(!dir.exists(json_data_dir)) { dir.create(json_data_dir) } files &lt;- list.files(json_data_dir) tweet_data.df &lt;- data.frame() for(file in files) { print(sprintf(&quot;File missing: %s&quot;, length(files) - which(file %in% files))) obj.r &lt;- jsonlite::read_json(sprintf(&quot;%s/%s&quot;, json_data_dir, file)) for (i in 1:length(obj.r$data)) { this_tweet.df &lt;- data.frame(id = obj.r$data[[i]]$id[[1]][[1]], author_id = obj.r$data[[i]]$author_id[[1]][[1]], created_at = obj.r$data[[i]]$created_at[[1]][[1]], lang = obj.r$data[[i]]$lang[[1]][[1]], reply_settings = obj.r$data[[i]]$reply_settings[[1]][[1]], source = obj.r$data[[i]]$source[[1]][[1]], possibly_sensitive = obj.r$data[[i]]$possibly_sensitive[[1]][[1]], conversation_id = obj.r$data[[i]]$conversation_id[[1]][[1]], text = obj.r$data[[i]]$text[[1]][[1]]) these_metrics &lt;- as.data.frame(obj.r$data[[i]]$public_metrics) colnames(these_metrics) &lt;- names(obj.r$data[[i]]$public_metrics) this_tweet.df &lt;- this_tweet.df %&gt;% dplyr::bind_cols(these_metrics) tweet_data.df &lt;- tweet_data.df %&gt;% dplyr::bind_rows(this_tweet.df) } } 3.2 Storage, analysis and acccess 3.3 Data ownership and ethics "],["search-tweets.html", "Chapter 4 Search tweets 4.1 Tweets from a given account", " Chapter 4 Search tweets Chapter progress bar ██████░░░░░░░░░░░░░░░░░░░░░░░░ 20% Let’s first specify where we plan to store our json data. Notably, we also take care of programmatically create the directory if this doesn’t exist (the ! in front of dir.exists is a logical negation (i.e. NOT)). json_data_dir &lt;- &quot;json_data&quot; if(!dir.exists(json_data_dir)) { dir.create(json_data_dir) } 4.1 Tweets from a given account url &lt;- &quot;https://api.twitter.com/2/tweets/search/all&quot; headers &lt;- c(`Authorization` = sprintf(&#39;Bearer %s&#39;, Sys.getenv(&quot;BEARER_TOKEN&quot;))) params &lt;- list(query = &quot;from:matteosalvinimi&quot;, start_time = &quot;2022-03-01T00:00:00Z&quot;, tweet.fields = &quot;attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,public_metrics,possibly_sensitive,referenced_tweets,reply_settings,source,text,withheld&quot;, expansions = &quot;attachments.poll_ids,attachments.media_keys,author_id,entities.mentions.username,geo.place_id,in_reply_to_user_id,referenced_tweets.id,referenced_tweets.id.author_id&quot;, user.fields = &quot;created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld&quot;, poll.fields = &quot;duration_minutes,end_datetime,id,options,voting_status&quot;, place.fields = &quot;contained_within,country,country_code,full_name,geo,id,name,place_type&quot;, media.fields = &quot;duration_ms,height,media_key,preview_image_url,type,url,width,public_metrics,alt_text&quot;, max_results = 100) If we don’t set an end_time, this is going to be default to now -30 seconds. res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.r &lt;- httr::content(res, as = &quot;text&quot;) %&gt;% jsonlite::fromJSON() jsonlite::write_json(httr::content(res, as = &quot;parsed&quot;), path = sprintf(&quot;%s/%s_%s.json&quot;, json_data_dir, obj.r$meta$oldest_id, obj.r$meta$newest_id)) Do we have additional pages? if (!is.null(obj.r$meta$next_token)) { while(TRUE) { params[[&#39;pagination_token&#39;]] &lt;- obj.r$meta$next_token print(sprintf(&quot;Next token: %s...&quot;, obj.r$meta$next_token)) res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.r &lt;- httr::content(res, as = &quot;text&quot;) %&gt;% jsonlite::fromJSON() if (!is.null(obj.r$status) &amp;&amp; obj.r$status == 429) { while(TRUE) { print(obj.r$title) Sys.sleep(60) res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.r &lt;- httr::content(res, as = &quot;text&quot;) %&gt;% jsonlite::fromJSON() if (is.null(obj.r$status)) { break } } } jsonlite::write_json(httr::content(res, as = &quot;parsed&quot;), path = sprintf(&quot;%s/%s_%s.json&quot;, json_data_dir, obj.r$meta$oldest_id, obj.r$meta$newest_id)) if (is.null(obj.r$meta$next_token)) { break } } } "],["filtered-stream.html", "Chapter 5 Filtered stream", " Chapter 5 Filtered stream Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["tweets-lookup.html", "Chapter 6 Tweets lookup", " Chapter 6 Tweets lookup Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["users-lookup.html", "Chapter 7 Users lookup", " Chapter 7 Users lookup Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["user-follows.html", "Chapter 8 User follows", " Chapter 8 User follows Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["user-friends.html", "Chapter 9 User friends", " Chapter 9 User friends Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["list-lookup.html", "Chapter 10 List lookup", " Chapter 10 List lookup Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["list-members.html", "Chapter 11 List members", " Chapter 11 List members Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["list-memberships.html", "Chapter 12 List memberships", " Chapter 12 List memberships Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
