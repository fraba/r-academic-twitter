[["index.html", "Twitter API Academic Research access with R Chapter 1 About 1.1 Book 1.2 Author", " Twitter API Academic Research access with R Francesco Bailo 2022-03-29 Chapter 1 About 1.1 Book This book offers some practical understanding on how to access the Twitter API with R. It assumes an Academic Research access but also some familiarity with R. If you are a student or an academic you can get more information on how to apply here. The book is based on the official Twitter documentation that you can access here. The code used in this book doesn’t rely on any ad-hoc package to access the Twitter API. This probably requries some more work on the user side but it also allows for more flexibility in defining and setting API queries and in responding to API changes. The code used in this book relies on three generalist packages The httr package (Wickham 2020) to deal with HTTP requests; The dplyr package (Wickham et al. 2021) to manipulate data objects in R; and The jsonlite package (Ooms 2022) to deal with JSON-formatted data objects. This book is very much a working in progress. For suggestions, comments or if you note a mistake, please create an issue here. 1.1.1 Twitter relationships In collecting Twitter data using the API, there are a number of entry points. Each node in the diagram indicate a possible entry point with arrows indicating the type of API requests necessary to crawl the graph. Of course there are many other entry points. A good place to see a complete list is the official Twitter API endpoint map. 1.2 Author Francesco Bailo is Lecturer of Digital and Social Media at the University of Technology Sydney, Australia. His research focuses on the use of digital and social media in politics. He obtained his PhD in 2017 at the University of Sydney, Australia. References "],["first-steps.html", "Chapter 2 First steps 2.1 Packages 2.2 Credentials 2.3 Interrogating the Twitter API 2.4 Twitter API v1.1 and Twitter API v2", " Chapter 2 First steps Chapter progress bar ███████████████████████████░░░ 90% 2.1 Packages The R code relies on generalist packages to access the API and manipulate the response. library(&quot;httr&quot;) library(&quot;dplyr&quot;) library(&quot;jsonlite&quot;) If you don’t have these packages already install, you need to run install.packages(&quot;httr&quot;) install.packages(&quot;jsonlite&quot;) install.packages(&quot;dplyr&quot;) 2.2 Credentials Let’s store our bearer token in an environment variable (let’s call it BEARER_TOKEN) Sys.setenv(BEARER_TOKEN = &quot;copy-your-bearer-token-here&quot;) We are then able to get the token back with Sys.getenv(&quot;BEARER_TOKEN&quot;) The idea is to run Sys.setenv() from our console before running our scripts (that is, every time!) so that our token is never added to a script file. Of course, if you don’t care you can just store it in a regular variable. 2.3 Interrogating the Twitter API The Twitter API accept two methods to exchange information: POST and GET. Intuitively, with the POST method we send information to a server while with the GET method we retrieve information. With the Twitter API, the GET method is used more frequently. Still, we need to use the POST method to define our search rules before we GET the Filtered stream. This is how a GET request using the httr package looks like: httr::GET(url, httr::add_headers(.headers = headers), query = params) The url is a simple character variable while headers and params are lists. But let’s send a GET request! We need first to set the URL, specify our request headers (these are not going to change, so you can place at the top of your document) and set the parameters fo the query. url &lt;- &quot;https://api.twitter.com/2/tweets/counts/recent&quot; headers &lt;- c(`Authorization` = sprintf(&#39;Bearer %s&#39;, Sys.getenv(&quot;BEARER_TOKEN&quot;))) params &lt;- list(query = &quot;from:TwitterDev&quot;, granularity = &quot;day&quot;) What are we doing here? With url we specify the endpoint we want to use for this API request. The Twitter API has several endpoints. Note that sometimes we need to include parameters here instead of passing them through the HTTP query. headers is the first layer of information that we send over to the server. In this case it contains our token. If this is accepted - the status of the request is 200 OK - then the API is ready to process our request. If the token is not accepted we get as status 401 Unauthorized. Note that these error codes and messages define the status of the HTTP request. The Twitter API has a different set of error codes. In this sense, we can get a 200 OK from the HTTP layer and still get an error (e.g. 429 Too Many Requests) from the API layer (think in stacks!). With params we define the queries with want to append to the URL. Functionally, you can imagine that the list of key-value pairs what we define in list object params are appended after the string we set with url and a ? (for example, in https://example.com/over/there?name=ferret the query is defined by the key-value name=ferret). Now we can add these as attributes to the function GET and collect the response in res. res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) By printing res we see details about the HTTP response (but not yet the API response or the content returned from the API). print(res) ## Response [https://api.twitter.com/2/tweets/counts/recent?query=from%3ATwitterDev&amp;granularity=day] ## Date: 2022-03-28 23:40 ## Status: 200 ## Content-Type: application/json; charset=utf-8 ## Size: 729 B If our request was authorised we should get Status: 200 if our request was not authorised (likely because your token was not correctly specified) we should instead get Status: 401 Assuming, that we got an OK from the HTTP layer, then we can access the content we receive as a response from the API layer. We access it with the function httr::content(). obj.json &lt;- httr::content(res, as = &quot;text&quot;) Now by default the Twitter API responses are in JSON format, which looks like this: print(jsonlite::prettify(obj.json, indent = 4)) ## { ## &quot;data&quot;: [ ## { ## &quot;end&quot;: &quot;2022-03-22T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-21T23:40:12.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-23T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-22T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-24T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-23T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 2 ## }, ## { ## &quot;end&quot;: &quot;2022-03-25T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-24T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 1 ## }, ## { ## &quot;end&quot;: &quot;2022-03-26T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-25T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-27T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-26T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-28T00:00:00.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-27T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 0 ## }, ## { ## &quot;end&quot;: &quot;2022-03-28T23:40:12.000Z&quot;, ## &quot;start&quot;: &quot;2022-03-28T00:00:00.000Z&quot;, ## &quot;tweet_count&quot;: 1 ## } ## ], ## &quot;meta&quot;: { ## &quot;total_tweet_count&quot;: 4 ## } ## } ## We can use the jsonlite package to translate the JSON-formatted string into an R object with obj.r &lt;- jsonlite::fromJSON(obj.json) print(obj.r) ## $data ## end start tweet_count ## 1 2022-03-22T00:00:00.000Z 2022-03-21T23:40:12.000Z 0 ## 2 2022-03-23T00:00:00.000Z 2022-03-22T00:00:00.000Z 0 ## 3 2022-03-24T00:00:00.000Z 2022-03-23T00:00:00.000Z 2 ## 4 2022-03-25T00:00:00.000Z 2022-03-24T00:00:00.000Z 1 ## 5 2022-03-26T00:00:00.000Z 2022-03-25T00:00:00.000Z 0 ## 6 2022-03-27T00:00:00.000Z 2022-03-26T00:00:00.000Z 0 ## 7 2022-03-28T00:00:00.000Z 2022-03-27T00:00:00.000Z 0 ## 8 2022-03-28T23:40:12.000Z 2022-03-28T00:00:00.000Z 1 ## ## $meta ## $meta$total_tweet_count ## [1] 4 And this is information on the number of tweets posted by @TwitterDev in the days before our request. 2.4 Twitter API v1.1 and Twitter API v2 Currently both the v1.1 and v2 version of the Twitter API are online and accepting requests. Still, not all endpoints available for the v1.1 are also already implemented in the v2. So we will need to use both endpoints. The main issue with that is that how API errors are returned in two different formats. The best way to see how errors are returned is… to trigger so error! 2.4.1 API v1.1 errrors Let’s get an API error first by requesting trends for a place that doesn’t exist. url &lt;- &quot;https://api.twitter.com/1.1/trends/place.json&quot; params &lt;- list(id = &quot;THIS_ID_DOESNT_EXIST&quot;) res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.json &lt;- httr::content(res, as = &quot;text&quot;) obj.r &lt;- jsonlite::fromJSON(obj.json) While using the API v1.1., you should expect to deal with such structure when you hit an error print(str(obj.r)) ## List of 1 ## $ errors:&#39;data.frame&#39;: 1 obs. of 2 variables: ## ..$ code : int 34 ## ..$ message: chr &quot;Sorry, that page does not exist.&quot; ## NULL obj.r is list containing a single data.frame in a list’s item named errors. To check if the result contains an error we can do \"errors\" %in% names(obj.r) which will return TRUE if we hit an API v1.1 error and FALSE if the API returned the information we requested. Let’s try it out: &quot;errors&quot; %in% names(obj.r) ## [1] TRUE but params &lt;- list(id = &quot;1&quot;) # This ID instead exists res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.json &lt;- httr::content(res, as = &quot;text&quot;) obj.r &lt;- jsonlite::fromJSON(obj.json) &quot;errors&quot; %in% names(obj.r) ## [1] FALSE 2.4.2 API v2 errrors We can then trigger an error from the v2 API with the following code. The structure of the response object is going to be different. url &lt;- &quot;https://api.twitter.com/2/tweets/counts/recent&quot; params &lt;- list(squery = &quot;The parameter&#39;s name is mispelled&quot;) res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.json &lt;- httr::content(res, as = &quot;text&quot;) obj.r &lt;- jsonlite::fromJSON(obj.json) print(str(obj.r)) ## List of 4 ## $ errors:&#39;data.frame&#39;: 2 obs. of 2 variables: ## ..$ parameters:&#39;data.frame&#39;: 2 obs. of 2 variables: ## .. ..$ query :List of 2 ## .. .. ..$ : list() ## .. .. ..$ : NULL ## .. ..$ squery:List of 2 ## .. .. ..$ : NULL ## .. .. ..$ : chr &quot;The parameter&#39;s name is mispelled&quot; ## ..$ message : chr [1:2] &quot;The `query` query parameter can not be empty&quot; &quot;The query parameter [squery] is not one of [query,start_time,end_time,since_id,until_id,next_token,pagination_t&quot;| __truncated__ ## $ title : chr &quot;Invalid Request&quot; ## $ detail: chr &quot;One or more parameters to your request was invalid.&quot; ## $ type : chr &quot;https://api.twitter.com/2/problems/invalid-request&quot; ## NULL but likely we can still check if our response generated an error with &quot;errors&quot; %in% names(obj.r) ## [1] TRUE "],["data-management.html", "Chapter 3 Data management 3.1 JSON 3.2 Storage, analysis and acccess 3.3 Data ownership and ethics", " Chapter 3 Data management Chapter progress bar ██████████░░░░░░░░░░░░░░░░░░░░ 35% Once we got access to the Twitter API we must start planning about data management. The Twitter API can potentially return a huge amount of data (the current limits for Academic access are set to 10,000,000 tweets a month). What do we do with it? Where do we store it but also should we store it? 3.1 JSON The default format for data loads from the Twitter API is JSON. A JSON (JavaScript Object Notation) file is a plain text file - so you can open it with any text editor. Information is structured through nesting like HTML or XML. JSON can’t be naturally manipulated in R. Access and analysis in R involves reading the text in but also transforming it into R vector types (e.g. logical, integer, double, character) and structures (e.g. atomic vector, data.frame, matrix, list) - which is not painless! 3.1.1 Read your JSON files: Tweets Let’s define the name of the directory where we want to receive our JSON files from the Twitter API. json_data_dir &lt;- &quot;json_data&quot; The following code will the parse through the json_data_dir, read in each JSON file and try to import tweets metadata into the data.frame tweet_data.df. Importantly, this code does not access the API but instead relies on data previously downloaded; this code will only work with tweet objects. You need a different code to import users or lists, for example. if(!dir.exists(json_data_dir)) { dir.create(json_data_dir) } files &lt;- list.files(json_data_dir) tweet_data.df &lt;- data.frame() for(file in files) { print(sprintf(&quot;File missing: %s&quot;, length(files) - which(file %in% files))) obj.r &lt;- jsonlite::read_json(sprintf(&quot;%s/%s&quot;, json_data_dir, file)) for (i in 1:length(obj.r$data)) { this_tweet.df &lt;- data.frame(id = obj.r$data[[i]]$id[[1]][[1]], author_id = obj.r$data[[i]]$author_id[[1]][[1]], created_at = obj.r$data[[i]]$created_at[[1]][[1]], lang = obj.r$data[[i]]$lang[[1]][[1]], reply_settings = obj.r$data[[i]]$reply_settings[[1]][[1]], source = obj.r$data[[i]]$source[[1]][[1]], possibly_sensitive = obj.r$data[[i]]$possibly_sensitive[[1]][[1]], conversation_id = obj.r$data[[i]]$conversation_id[[1]][[1]], text = obj.r$data[[i]]$text[[1]][[1]]) these_metrics &lt;- as.data.frame(obj.r$data[[i]]$public_metrics) colnames(these_metrics) &lt;- names(obj.r$data[[i]]$public_metrics) this_tweet.df &lt;- this_tweet.df %&gt;% dplyr::bind_cols(these_metrics) tweet_data.df &lt;- tweet_data.df %&gt;% dplyr::bind_rows(this_tweet.df) } } 3.2 Storage, analysis and acccess 3.3 Data ownership and ethics "],["search-tweets.html", "Chapter 4 Search tweets 4.1 Tweets from a given account", " Chapter 4 Search tweets Chapter progress bar ██████░░░░░░░░░░░░░░░░░░░░░░░░ 20% Let’s first specify where we plan to store our json data. Notably, we also take care of programmatically create the directory if this doesn’t exist (the ! in front of dir.exists is a logical negation (i.e. NOT)). json_data_dir &lt;- &quot;json_data&quot; if(!dir.exists(json_data_dir)) { dir.create(json_data_dir) } 4.1 Tweets from a given account url &lt;- &quot;https://api.twitter.com/2/tweets/search/all&quot; headers &lt;- c(`Authorization` = sprintf(&#39;Bearer %s&#39;, Sys.getenv(&quot;BEARER_TOKEN&quot;))) params &lt;- list(query = &quot;from:matteosalvinimi&quot;, start_time = &quot;2022-03-01T00:00:00Z&quot;, tweet.fields = &quot;attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,public_metrics,possibly_sensitive,referenced_tweets,reply_settings,source,text,withheld&quot;, expansions = &quot;attachments.poll_ids,attachments.media_keys,author_id,entities.mentions.username,geo.place_id,in_reply_to_user_id,referenced_tweets.id,referenced_tweets.id.author_id&quot;, user.fields = &quot;created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld&quot;, poll.fields = &quot;duration_minutes,end_datetime,id,options,voting_status&quot;, place.fields = &quot;contained_within,country,country_code,full_name,geo,id,name,place_type&quot;, media.fields = &quot;duration_ms,height,media_key,preview_image_url,type,url,width,public_metrics,alt_text&quot;, max_results = 100) If we don’t set an end_time, this is going to be default to now -30 seconds. res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.r &lt;- httr::content(res, as = &quot;text&quot;) %&gt;% jsonlite::fromJSON() jsonlite::write_json(httr::content(res, as = &quot;parsed&quot;), path = sprintf(&quot;%s/%s_%s.json&quot;, json_data_dir, obj.r$meta$oldest_id, obj.r$meta$newest_id)) Do we have additional pages? if (!is.null(obj.r$meta$next_token)) { while(TRUE) { params[[&#39;pagination_token&#39;]] &lt;- obj.r$meta$next_token print(sprintf(&quot;Next token: %s...&quot;, obj.r$meta$next_token)) res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.r &lt;- httr::content(res, as = &quot;text&quot;) %&gt;% jsonlite::fromJSON() if (!is.null(obj.r$status) &amp;&amp; obj.r$status == 429) { while(TRUE) { print(obj.r$title) Sys.sleep(60) res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.r &lt;- httr::content(res, as = &quot;text&quot;) %&gt;% jsonlite::fromJSON() if (is.null(obj.r$status)) { break } } } jsonlite::write_json(httr::content(res, as = &quot;parsed&quot;), path = sprintf(&quot;%s/%s_%s.json&quot;, json_data_dir, obj.r$meta$oldest_id, obj.r$meta$newest_id)) if (is.null(obj.r$meta$next_token)) { break } } } "],["filtered-stream.html", "Chapter 5 Filtered stream", " Chapter 5 Filtered stream Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["tweets-lookup.html", "Chapter 6 Tweets lookup", " Chapter 6 Tweets lookup Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["users-lookup.html", "Chapter 7 Users lookup", " Chapter 7 Users lookup Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["user-follows.html", "Chapter 8 User follows", " Chapter 8 User follows Chapter progress bar ███████████████████████████░░░ 90% There are different ways to get the users that a given user follows. If we are interested in getting only the Twitter user_id of each user out entry point user follows we can use this API endpoint (at this time a corresponding v2 version is not available as far as I know) url &lt;- &quot;https://api.twitter.com/1.1/friends/ids.json&quot; and this parameters entry_point_user_id &lt;- &#39;2962620002&#39; params &lt;- list(user_id = entry_point_user_id, count = 5000) The only required parameter is the user_id or alternatively screen_name. We store the JSON-formatted results into a data folder which we set with json_data_dir &lt;- &quot;json_data&quot; if(!dir.exists(json_data_dir)) { dir.create(json_data_dir) } We are now ready to request a paginate the results (in case we our entry point user follows more than 5,000 users). headers &lt;- c(`Authorization` = sprintf(&#39;Bearer %s&#39;, Sys.getenv(&quot;BEARER_TOKEN&quot;))) res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.r &lt;- httr::content(res, as = &quot;text&quot;) %&gt;% jsonlite::fromJSON() jsonlite::write_json(httr::content(res, as = &quot;parsed&quot;), path = sprintf(&quot;%s/%s_follows_ids_%s.json&quot;, json_data_dir, entry_point_user_id, sprintf(&quot;%04d&quot;, 1))) Do we have additional pages? if (obj.r$next_cursor != 0) { counter &lt;- 2 while(TRUE) { params[[&#39;cursor&#39;]] &lt;- obj.r$next_cursor_str print(sprintf(&quot;Next cursor: %s...&quot;, obj.r$next_cursor_str)) res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.r &lt;- httr::content(res, as = &quot;text&quot;) %&gt;% jsonlite::fromJSON() if (!is.null(obj.r$error) &amp;&amp; obj.r$error[&#39;code&#39;] == 88) { while(TRUE) { print(obj.r$errors) Sys.sleep(60) res &lt;- httr::GET(url, httr::add_headers(.headers = headers), query = params) obj.r &lt;- httr::content(res, as = &quot;text&quot;) %&gt;% jsonlite::fromJSON() if (is.null(obj.r$errors)) { break } } } jsonlite::write_json(httr::content(res, as = &quot;parsed&quot;), path = sprintf(&quot;%s/%s_follows_ids_%s.json&quot;, json_data_dir, entry_point_user_id, sprintf(&quot;%04d&quot;, counter))) if (obj.r$next_cursor == 0) { break } counter &lt;- counter + 1 } } "],["user-friends.html", "Chapter 9 User friends", " Chapter 9 User friends Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["list-lookup.html", "Chapter 10 List lookup", " Chapter 10 List lookup Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["list-members.html", "Chapter 11 List members", " Chapter 11 List members Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["list-memberships.html", "Chapter 12 List memberships", " Chapter 12 List memberships Chapter progress bar ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 0% "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
